{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e8e15-595d-43a5-827f-7ebc3e6b067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import dgl\n",
    "import random\n",
    "import copy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sumolib\n",
    "import traci\n",
    "import os\n",
    "import subprocess\n",
    "from typing import List, Dict\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "from dgl.data.utils import save_graphs\n",
    "\n",
    "class MarkovServiceDemand:\n",
    "    def __init__(self, services: List[str]):\n",
    "        self.services = services + ['none']  # Include 'none' as a state\n",
    "        self.transition_matrix = self._create_transition_matrix()\n",
    "        self.current_services = {}  # Current state per vehicle\n",
    "        self.poisson_triggered = set()  # Vehicles that already triggered Poisson\n",
    "        \n",
    "    def _create_transition_matrix(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Transition matrix between services (including 'none')\"\"\"\n",
    "        return {\n",
    "            'none': {\n",
    "                'cooperative_perception': 0.15, \n",
    "                'platooning_control': 0.25, \n",
    "                'edge_object_recognition': 0.08, \n",
    "                'predictive_collision_avoidance': 0.07, \n",
    "                'infrastructure_vision': 0.05, \n",
    "                'none': 0.4\n",
    "            },\n",
    "            'cooperative_perception': {\n",
    "                'cooperative_perception': 0.6, \n",
    "                'platooning_control': 0.08, \n",
    "                'edge_object_recognition': 0.04, \n",
    "                'predictive_collision_avoidance': 0.03, \n",
    "                'infrastructure_vision': 0.02, \n",
    "                'none': 0.23\n",
    "            },\n",
    "            'platooning_control': {\n",
    "                'cooperative_perception': 0.05, \n",
    "                'platooning_control': 0.7, \n",
    "                'edge_object_recognition': 0.04, \n",
    "                'predictive_collision_avoidance': 0.08, \n",
    "                'infrastructure_vision': 0.03, \n",
    "                'none': 0.1\n",
    "            },\n",
    "            'edge_object_recognition': {\n",
    "                'cooperative_perception': 0.08, \n",
    "                'platooning_control': 0.08, \n",
    "                'edge_object_recognition': 0.55, \n",
    "                'predictive_collision_avoidance': 0.12, \n",
    "                'infrastructure_vision': 0.07, \n",
    "                'none': 0.1\n",
    "            },\n",
    "            'predictive_collision_avoidance': {\n",
    "                'cooperative_perception': 0.04, \n",
    "                'platooning_control': 0.08, \n",
    "                'edge_object_recognition': 0.08, \n",
    "                'predictive_collision_avoidance': 0.65, \n",
    "                'infrastructure_vision': 0.05, \n",
    "                'none': 0.1\n",
    "            },\n",
    "            'infrastructure_vision': {\n",
    "                'cooperative_perception': 0.01, \n",
    "                'platooning_control': 0.02, \n",
    "                'edge_object_recognition': 0.02, \n",
    "                'predictive_collision_avoidance': 0.05, \n",
    "                'infrastructure_vision': 0.85, \n",
    "                'none': 0.05\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def initialize_vehicle(self, vid: str, vehicle_data: Dict) -> str:\n",
    "        \"\"\"Initialize a vehicle with Poisson distribution (only once)\"\"\"\n",
    "        if vid not in self.poisson_triggered:\n",
    "            self.poisson_triggered.add(vid)\n",
    "            \n",
    "            # Poisson distribution to decide initial service\n",
    "            k = np.random.poisson(0.5)  # Œª = 0.5 for less aggressive\n",
    "            if k >= 1:\n",
    "                # Choose initial service based on context\n",
    "                initial_service = self._get_initial_service(vehicle_data)\n",
    "                self.current_services[vid] = initial_service\n",
    "                return initial_service\n",
    "            else:\n",
    "                # No initial service\n",
    "                self.current_services[vid] = 'none'\n",
    "                return 'none'\n",
    "        else:\n",
    "            # Vehicle already initialized, use current state\n",
    "            return self.current_services.get(vid, 'none')\n",
    "    \n",
    "    def _get_initial_service(self, vehicle_data: Dict) -> str:\n",
    "        \"\"\"Determine initial service based on vehicle type\"\"\"\n",
    "        vehicle_type = vehicle_data.get('vehicle_type', 'car')\n",
    "        \n",
    "        initial_probs = {\n",
    "            'car': {\n",
    "                'cooperative_perception': 0.3, \n",
    "                'platooning_control': 0.4, \n",
    "                'edge_object_recognition': 0.15, \n",
    "                'predictive_collision_avoidance': 0.1, \n",
    "                'infrastructure_vision': 0.05\n",
    "            },\n",
    "            'truck': {\n",
    "                'cooperative_perception': 0.1, \n",
    "                'platooning_control': 0.3, \n",
    "                'edge_object_recognition': 0.2, \n",
    "                'predictive_collision_avoidance': 0.35, \n",
    "                'infrastructure_vision': 0.05\n",
    "            },\n",
    "            'bus': {\n",
    "                'cooperative_perception': 0.15, \n",
    "                'platooning_control': 0.35, \n",
    "                'edge_object_recognition': 0.15, \n",
    "                'predictive_collision_avoidance': 0.3, \n",
    "                'infrastructure_vision': 0.05\n",
    "            },\n",
    "            'emergency': {\n",
    "                'cooperative_perception': 0.05, \n",
    "                'platooning_control': 0.2, \n",
    "                'edge_object_recognition': 0.1, \n",
    "                'predictive_collision_avoidance': 0.15, \n",
    "                'infrastructure_vision': 0.5\n",
    "            },\n",
    "            'motorcycle': {\n",
    "                'cooperative_perception': 0.25, \n",
    "                'platooning_control': 0.45, \n",
    "                'edge_object_recognition': 0.15, \n",
    "                'predictive_collision_avoidance': 0.1, \n",
    "                'infrastructure_vision': 0.05\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        probs = initial_probs.get(vehicle_type, initial_probs['car'])\n",
    "        return random.choices(list(probs.keys()), weights=list(probs.values()))[0]\n",
    "    \n",
    "    def get_next_service(self, vid: str, vehicle_data: Dict) -> str:\n",
    "        \"\"\"Markov transition to next service\"\"\"\n",
    "        current = self.current_services.get(vid, 'none')\n",
    "        \n",
    "        # Get transition probabilities\n",
    "        next_probs = self.transition_matrix[current].copy()\n",
    "        \n",
    "        # Adjust based on vehicle context\n",
    "        next_probs = self._adjust_for_context(next_probs, vehicle_data)\n",
    "        \n",
    "        # Choose next service\n",
    "        next_service = random.choices(\n",
    "            list(next_probs.keys()), \n",
    "            weights=list(next_probs.values())\n",
    "        )[0]\n",
    "        \n",
    "        # Update state\n",
    "        self.current_services[vid] = next_service\n",
    "        return next_service\n",
    "    \n",
    "    def _adjust_for_context(self, probabilities: Dict[str, float], vehicle_data: Dict) -> Dict[str, float]:\n",
    "        \"\"\"Adjust probabilities based on vehicle context\"\"\"\n",
    "        adjusted = probabilities.copy()\n",
    "        vehicle_type = vehicle_data.get('vehicle_type', 'car')\n",
    "        speed = vehicle_data.get('speed', 0)\n",
    "        \n",
    "        # Adjustments based on vehicle type\n",
    "        if vehicle_type == 'emergency':\n",
    "            adjusted['infrastructure_vision'] *= 2.5\n",
    "            adjusted['predictive_collision_avoidance'] *= 1.5\n",
    "        elif vehicle_type in ['truck', 'bus']:\n",
    "            adjusted['predictive_collision_avoidance'] *= 2.0\n",
    "            adjusted['platooning_control'] *= 1.3\n",
    "            \n",
    "        # Adjustments based on speed\n",
    "        if speed < 10:  # Traffic jam\n",
    "            adjusted['cooperative_perception'] *= 1.8\n",
    "            adjusted['platooning_control'] *= 0.7\n",
    "        elif speed > 60:  # Highway\n",
    "            adjusted['platooning_control'] *= 1.5\n",
    "            adjusted['predictive_collision_avoidance'] *= 1.3\n",
    "            \n",
    "        # Renormalize\n",
    "        total = sum(adjusted.values())\n",
    "        for service in adjusted:\n",
    "            adjusted[service] /= total\n",
    "            \n",
    "        return adjusted\n",
    "    \n",
    "    def get_service_duration(self, service: str) -> int:\n",
    "        \"\"\"Service lifetime duration\"\"\"\n",
    "        base_durations = {\n",
    "            'cooperative_perception': np.random.exponential(1/0.08),\n",
    "            'platooning_control': np.random.exponential(1/0.12),\n",
    "            'edge_object_recognition': np.random.exponential(1/0.05),\n",
    "            'predictive_collision_avoidance': np.random.exponential(1/0.1),\n",
    "            'infrastructure_vision': np.random.exponential(1/0.15),\n",
    "            'none': np.random.exponential(1/0.05)\n",
    "        }\n",
    "        return max(1, int(base_durations.get(service, 10)))\n",
    "\n",
    "class CombinedVehicleManager:\n",
    "    def __init__(self, services: List[str], service_specs: Dict[str, Dict], \n",
    "                 target_vehicles: int, demand_model: MarkovServiceDemand,\n",
    "                 network_file: str = \"manhattan.net.xml\",\n",
    "                 route_file: str = \"manhattan.rou.xml\",\n",
    "                 use_gui: bool = True):\n",
    "        \n",
    "        self.services = services\n",
    "        self.service_specs = service_specs\n",
    "        self.target_vehicles = target_vehicles\n",
    "        self.demand_model = demand_model\n",
    "        self.current_vehicles = {}\n",
    "        self.vehicle_counter = 0\n",
    "        self.first_appearance_timestamps = {}\n",
    "        self.service_durations = {}\n",
    "\n",
    "        self.vehicle_specs = {\n",
    "            \"car\": {\"length\": 4.3, \"max_speed\": 50, \"accel\": 2.6, \"decel\": 4.5},\n",
    "            \"truck\": {\"length\": 12.0, \"max_speed\": 40, \"accel\": 1.3, \"decel\": 3.5},\n",
    "            \"bus\": {\"length\": 14.0, \"max_speed\": 36, \"accel\": 1.2, \"decel\": 3.0},\n",
    "            \"motorcycle\": {\"length\": 2.5, \"max_speed\": 60, \"accel\": 3.0, \"decel\": 6.0},\n",
    "            \"emergency\": {\"length\": 6.0, \"max_speed\": 70, \"accel\": 3.5, \"decel\": 6.5}\n",
    "        }\n",
    "\n",
    "        # Close existing connections\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # ‚úÖ USING EXISTING NETWORK\n",
    "        if not os.path.exists(network_file):\n",
    "            print(f\"‚ùå Network file {network_file} not found\")\n",
    "            self.sumo = None\n",
    "            self.net = None\n",
    "            return\n",
    "        \n",
    "        # Load YOUR Manhattan network\n",
    "        try:\n",
    "            self.net = sumolib.net.readNet(network_file)\n",
    "            print(f\"‚úÖ YOUR Manhattan network loaded: {len(self.net.getNodes())} nodes, {len(self.net.getEdges())} edges\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading network: {e}\")\n",
    "            self.sumo = None\n",
    "            self.net = None\n",
    "            return\n",
    "        \n",
    "        # ‚úÖ ROUTE FILES VERIFICATION\n",
    "        if not os.path.exists(route_file):\n",
    "            print(f\"üîÑ Creating routes for your Manhattan network...\")\n",
    "            self._generate_routes_for_existing_network(target_vehicles, route_file)\n",
    "        else:\n",
    "            print(f\"‚úÖ Existing route file used: {route_file}\")\n",
    "        \n",
    "        # SUMO configuration with YOUR files\n",
    "        self.sumo_config = self._create_sumo_config(network_file, route_file)\n",
    "        \n",
    "        try:\n",
    "            if use_gui:\n",
    "                print(\"üöó Starting SUMO-GUI with YOUR network...\")\n",
    "                traci.start(['sumo-gui', '-c', self.sumo_config, '--start', '--delay', '100'])\n",
    "            else:\n",
    "                print(\"üöó Starting SUMO (console mode) with YOUR network...\")\n",
    "                traci.start(['sumo', '-c', self.sumo_config])\n",
    "            \n",
    "            self.sumo = traci\n",
    "            print(\"‚úÖ SUMO started with YOUR Manhattan network\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå SUMO error: {e}\")\n",
    "            self.sumo = None\n",
    "\n",
    "    def _generate_routes_for_existing_network(self, num_vehicles: int, route_file: str):\n",
    "        \"\"\"Generate routes adapted to YOUR existing Manhattan network\"\"\"\n",
    "        routes_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<routes>\n",
    "    <vType id=\"car\" length=\"4.3\" maxSpeed=\"13.89\" accel=\"2.6\" decel=\"4.5\" sigma=\"0.5\" color=\"yellow\"/>\n",
    "    <vType id=\"truck\" length=\"12.0\" maxSpeed=\"11.11\" accel=\"1.3\" decel=\"3.5\" sigma=\"0.7\" color=\"red\"/>\n",
    "    <vType id=\"bus\" length=\"14.0\" maxSpeed=\"10.0\" accel=\"1.2\" decel=\"3.0\" sigma=\"0.8\" color=\"blue\"/>\n",
    "    <vType id=\"motorcycle\" length=\"2.5\" maxSpeed=\"16.67\" accel=\"3.0\" decel=\"6.0\" sigma=\"0.3\" color=\"green\"/>\n",
    "    <vType id=\"emergency\" length=\"6.0\" maxSpeed=\"19.44\" accel=\"3.5\" decel=\"6.5\" sigma=\"0.2\" color=\"white\"/>\n",
    "\"\"\"\n",
    "        \n",
    "        # Get edges from YOUR network\n",
    "        edges = [edge.getID() for edge in self.net.getEdges() \n",
    "                if not edge.getID().startswith(':')]\n",
    "        \n",
    "        print(f\"üîç YOUR network has {len(edges)} available edges\")\n",
    "        \n",
    "        vehicle_types = [\"car\", \"truck\", \"bus\", \"motorcycle\", \"emergency\"]\n",
    "        type_probabilities = [0.65, 0.15, 0.08, 0.10, 0.02]\n",
    "        \n",
    "        # Generate realistic routes for Manhattan\n",
    "        routes = []\n",
    "        for i in range(num_vehicles):\n",
    "            route_edges = self._create_manhattan_style_route(edges)\n",
    "            routes.append(route_edges)\n",
    "        \n",
    "        # Staggered departures\n",
    "        departure_times = sorted([random.uniform(0, 500) for _ in range(num_vehicles)])\n",
    "        \n",
    "        for i, depart in enumerate(departure_times):\n",
    "            route_edges = routes[i] if i < len(routes) else [random.choice(edges)]\n",
    "            vtype = random.choices(vehicle_types, weights=type_probabilities, k=1)[0]\n",
    "            \n",
    "            routes_content += f\"\"\"\n",
    "    <route id=\"route_{i}\" edges=\"{' '.join(route_edges)}\"/>\n",
    "    <vehicle id=\"veh{i}\" type=\"{vtype}\" depart=\"{depart:.1f}\" route=\"route_{i}\"/>\"\"\"\n",
    "        \n",
    "        routes_content += \"\\n</routes>\"\n",
    "        \n",
    "        with open(route_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(routes_content)\n",
    "        print(f\"‚úÖ Routes generated for YOUR Manhattan: {route_file}\")\n",
    "\n",
    "    def _create_manhattan_style_route(self, edges: List[str]) -> List[str]:\n",
    "        \"\"\"Create a typical Manhattan route (grid movements)\"\"\"\n",
    "        try:\n",
    "            # Separate horizontal and vertical edges\n",
    "            horizontal_edges = []\n",
    "            vertical_edges = []\n",
    "            \n",
    "            for edge_id in edges:\n",
    "                edge_obj = self.net.getEdge(edge_id)\n",
    "                from_node = edge_obj.getFromNode()\n",
    "                to_node = edge_obj.getToNode()\n",
    "                \n",
    "                # Determine if edge is horizontal or vertical\n",
    "                if abs(from_node.getCoord()[0] - to_node.getCoord()[0]) > abs(from_node.getCoord()[1] - to_node.getCoord()[1]):\n",
    "                    horizontal_edges.append(edge_id)\n",
    "                else:\n",
    "                    vertical_edges.append(edge_id)\n",
    "            \n",
    "            # Create a grid path (ex: 2 horizontals, 1 vertical, 2 horizontals)\n",
    "            route = []\n",
    "            if horizontal_edges and vertical_edges:\n",
    "                # Start with horizontal\n",
    "                route.append(random.choice(horizontal_edges))\n",
    "                # Then vertical  \n",
    "                route.append(random.choice(vertical_edges))\n",
    "                # Then another horizontal\n",
    "                route.append(random.choice(horizontal_edges))\n",
    "            else:\n",
    "                # Fallback if not enough edges\n",
    "                route = random.sample(edges, min(3, len(edges)))\n",
    "            \n",
    "            return route\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Manhattan route creation error: {e}\")\n",
    "            return random.sample(edges, min(3, len(edges)))\n",
    "\n",
    "    def _create_sumo_config(self, network_file: str, route_file: str) -> str:\n",
    "        \"\"\"Create SUMO configuration with optimized parameters\"\"\"\n",
    "        config_content = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<configuration>\n",
    "    <input>\n",
    "        <net-file value=\"{network_file}\"/>\n",
    "        <route-files value=\"{route_file}\"/>\n",
    "    </input>\n",
    "    <time>\n",
    "        <begin value=\"0\"/>\n",
    "        <end value=\"10000\"/>\n",
    "    </time>\n",
    "    <processing>\n",
    "        <step-length value=\"1.0\"/>\n",
    "        <no-step-log value=\"true\"/>\n",
    "        <ignore-route-errors value=\"true\"/>\n",
    "        <no-internal-links value=\"false\"/>\n",
    "    </processing>\n",
    "    <report>\n",
    "        <no-warnings value=\"false\"/>\n",
    "        <verbose value=\"true\"/>\n",
    "    </report>\n",
    "</configuration>\"\"\"\n",
    "        \n",
    "        config_file = \"manhattan_config.sumocfg\"\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(config_content)\n",
    "        \n",
    "        return config_file\n",
    "\n",
    "    def _get_markov_service(self, vid: str, vehicle_data: Dict) -> str:\n",
    "        \"\"\"Use Markov model to get service\"\"\"\n",
    "        if vid not in self.demand_model.current_services:\n",
    "            # Initialization with Poisson (only once)\n",
    "            service = self.demand_model.initialize_vehicle(vid, vehicle_data)\n",
    "        else:\n",
    "            # Normal Markov transition\n",
    "            service = self.demand_model.get_next_service(vid, vehicle_data)\n",
    "        \n",
    "        # Update lifetime duration\n",
    "        if service != 'none':\n",
    "            self.service_durations[vid] = self.demand_model.get_service_duration(service)\n",
    "        else:\n",
    "            self.service_durations[vid] = 0\n",
    "            \n",
    "        return service\n",
    "\n",
    "    def update(self, t: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Update simulation with realistic service management\"\"\"\n",
    "        if self.sumo is None:\n",
    "            return self._empty_tensor_dict()\n",
    "        \n",
    "        try:\n",
    "            self.sumo.simulationStep()\n",
    "            \n",
    "            # Vehicle count control\n",
    "            current_count = len(self.sumo.vehicle.getIDList())\n",
    "            if current_count < self.target_vehicles:\n",
    "                to_add = self.target_vehicles - current_count\n",
    "                self._add_vehicles_safe(to_add)\n",
    "            elif current_count > self.target_vehicles:\n",
    "                to_remove = current_count - self.target_vehicles\n",
    "                self._remove_vehicles_safe(to_remove)\n",
    "            \n",
    "            # Update vehicles with realistic services\n",
    "            updated_vehicles = {}\n",
    "            for vid in self.sumo.vehicle.getIDList():\n",
    "                try:\n",
    "                    pos = self.sumo.vehicle.getPosition(vid)\n",
    "                    x, y = pos\n",
    "                    \n",
    "                    speed = self.sumo.vehicle.getSpeed(vid)\n",
    "                    road_id = self.sumo.vehicle.getRoadID(vid)\n",
    "                    vehicle_type = self.sumo.vehicle.getTypeID(vid)\n",
    "                    \n",
    "                    vehicle_data = {\n",
    "                        'vehicle_type': vehicle_type,\n",
    "                        'speed': speed,\n",
    "                        'road_id': road_id\n",
    "                    }\n",
    "                    \n",
    "                    if vid in self.current_vehicles:\n",
    "                        first_appearance = self.first_appearance_timestamps.get(vid, t)\n",
    "                        current_service = self.current_vehicles[vid]['service']\n",
    "                        \n",
    "                        if vid in self.service_durations and self.service_durations[vid] > 0:\n",
    "                            # Active service, decrement duration\n",
    "                            self.service_durations[vid] -= 1\n",
    "                            service = current_service  # Keep current service\n",
    "                        else:\n",
    "                            # Service expired or no service, Markov transition\n",
    "                            service = self._get_markov_service(vid, vehicle_data)\n",
    "                    else:\n",
    "                        # New vehicle - Markov initialization\n",
    "                        first_appearance = t\n",
    "                        self.first_appearance_timestamps[vid] = first_appearance\n",
    "                        \n",
    "                        # ‚úÖ Single initialization with integrated Poisson\n",
    "                        service = self._get_markov_service(vid, vehicle_data)\n",
    "                    \n",
    "                    # Prepare vehicle data\n",
    "                    vehicle_info = {\n",
    "                        'id': hash(vid) % 1000000,\n",
    "                        'sumo_id': vid,\n",
    "                        'position': torch.tensor([x, y], dtype=torch.float),\n",
    "                        'service': service,\n",
    "                        'cpu_demand': self.service_specs[service]['cpu'] if service != 'none' else 0,\n",
    "                        'ram_demand': self.service_specs[service]['ram'] if service != 'none' else 0,\n",
    "                        'data_size': self.service_specs[service]['data_size'] if service != 'none' else 0,\n",
    "                        'speed': speed,\n",
    "                        'vehicle_type': vehicle_type,\n",
    "                        'road_id': road_id,\n",
    "                        'timestamp': t,\n",
    "                        'timestamp_apparition': first_appearance,\n",
    "                        'service_remaining_duration': self.service_durations.get(vid, 0)\n",
    "                    }\n",
    "                    \n",
    "                    updated_vehicles[vid] = vehicle_info\n",
    "                    \n",
    "                except traci.TraCIException:\n",
    "                    continue\n",
    "            \n",
    "            self.current_vehicles = updated_vehicles\n",
    "            return self._to_tensor_format()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during SUMO update: {e}\")\n",
    "            return self._empty_tensor_dict()\n",
    "\n",
    "    def _add_vehicles_safe(self, num_to_add: int):\n",
    "        \"\"\"Add vehicles with robust error handling\"\"\"\n",
    "        if not hasattr(self, 'net') or self.net is None:\n",
    "            return\n",
    "            \n",
    "        edges = [edge.getID() for edge in self.net.getEdges() if not edge.getID().startswith(':')]\n",
    "        if not edges:\n",
    "            return\n",
    "            \n",
    "        vehicle_types = [\"car\", \"truck\", \"bus\", \"motorcycle\", \"emergency\"]\n",
    "        \n",
    "        for i in range(num_to_add):\n",
    "            try:\n",
    "                # Simple route between two valid edges\n",
    "                start_edge = random.choice(edges)\n",
    "                end_edge = random.choice(edges)\n",
    "                \n",
    "                route_id = f\"dynamic_route_{self.vehicle_counter}\"\n",
    "                veh_id = f\"dynamic_veh_{self.vehicle_counter}\"\n",
    "                chosen_type = random.choice(vehicle_types)\n",
    "                \n",
    "                # Create simple route\n",
    "                self.sumo.route.add(route_id, [start_edge, end_edge])\n",
    "                self.sumo.vehicle.add(veh_id, route_id, typeID=chosen_type, depart=\"now\")\n",
    "                \n",
    "                self.vehicle_counter += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error adding vehicle {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "    def _remove_vehicles_safe(self, num_to_remove: int):\n",
    "        \"\"\"Safely remove vehicles\"\"\"\n",
    "        vehicles = self.sumo.vehicle.getIDList()\n",
    "        if vehicles:\n",
    "            vehicles_to_remove = random.sample(vehicles, min(num_to_remove, len(vehicles)))\n",
    "            for vid in vehicles_to_remove:\n",
    "                try:\n",
    "                    self.sumo.vehicle.remove(vid)\n",
    "                    if vid in self.current_vehicles:\n",
    "                        del self.current_vehicles[vid]\n",
    "                    if vid in self.service_durations:\n",
    "                        del self.service_durations[vid]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    def _to_tensor_format(self) -> Dict[str, torch.Tensor]:\n",
    "        all_vehicle_types = [\"car\", \"truck\", \"bus\", \"motorcycle\", \"emergency\"]\n",
    "        all_services = self.services + ['none']\n",
    "        \n",
    "        if not self.current_vehicles:\n",
    "            return self._empty_tensor_dict()\n",
    "        \n",
    "        return {\n",
    "            'id': torch.tensor([v['id'] for v in self.current_vehicles.values()]),\n",
    "            'position': torch.stack([v['position'] for v in self.current_vehicles.values()]),\n",
    "            'type_service': torch.tensor([all_services.index(v['service']) for v in self.current_vehicles.values()]),\n",
    "            'vehicle_type': torch.tensor([all_vehicle_types.index(v['vehicle_type']) for v in self.current_vehicles.values()]), \n",
    "            'cpu_demand': torch.tensor([v['cpu_demand'] for v in self.current_vehicles.values()]),\n",
    "            'ram_demand': torch.tensor([v['ram_demand'] for v in self.current_vehicles.values()]),\n",
    "            'data_size': torch.tensor([v['data_size'] for v in self.current_vehicles.values()]),\n",
    "            'speed': torch.tensor([v['speed'] for v in self.current_vehicles.values()]),\n",
    "            'timestamp_apparition': torch.tensor([v['timestamp_apparition'] for v in self.current_vehicles.values()]),\n",
    "            'timestamp': torch.tensor([v['timestamp'] for v in self.current_vehicles.values()]),\n",
    "            'service_remaining_duration': torch.tensor([v['service_remaining_duration'] for v in self.current_vehicles.values()])\n",
    "        }\n",
    "\n",
    "    def _empty_tensor_dict(self):\n",
    "        return {\n",
    "            'id': torch.tensor([], dtype=torch.long),\n",
    "            'position': torch.tensor([], dtype=torch.float).reshape(0, 2),\n",
    "            'type_service': torch.tensor([], dtype=torch.long),\n",
    "            'vehicle_type': torch.tensor([], dtype=torch.long),\n",
    "            'cpu_demand': torch.tensor([], dtype=torch.float),\n",
    "            'ram_demand': torch.tensor([], dtype=torch.float),\n",
    "            'data_size': torch.tensor([], dtype=torch.float),\n",
    "            'speed': torch.tensor([], dtype=torch.float),\n",
    "            'timestamp_apparition': torch.tensor([], dtype=torch.long),\n",
    "            'timestamp': torch.tensor([], dtype=torch.long),\n",
    "            'service_remaining_duration': torch.tensor([], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class CombinedDocumentSimulator:\n",
    "    def __init__(self, num_edges=8, target_vehicles=30, time_steps=230, \n",
    "                 network_file=\"manhattan.net.xml\", use_gui=True,\n",
    "                 save_snapshots: bool = True, output_file: str = \"snapshots.bin\"):\n",
    "        self.num_edges = num_edges\n",
    "        self.time_steps = time_steps\n",
    "        self.services = [\n",
    "            'cooperative_perception', \n",
    "            'platooning_control', \n",
    "            'edge_object_recognition',\n",
    "            'predictive_collision_avoidance',\n",
    "            'infrastructure_vision'\n",
    "        ]\n",
    "        \n",
    "        self.service_specs = {\n",
    "            'cooperative_perception': {'cpu': 15, 'ram': 10, 'data_size': 2},\n",
    "            'platooning_control': {'cpu': 7, 'ram': 5, 'data_size': 1.6},\n",
    "            'edge_object_recognition': {'cpu': 5, 'ram': 3, 'data_size': 1},\n",
    "            'predictive_collision_avoidance': {'cpu': 10, 'ram': 7, 'data_size': 1.8},\n",
    "            'infrastructure_vision': {'cpu': 3, 'ram': 2, 'data_size': 0.6},\n",
    "            'none': {'cpu': 0, 'ram': 0, 'data_size': 0}\n",
    "        }\n",
    "\n",
    "        self.save_snapshots = save_snapshots\n",
    "        self.output_file = output_file\n",
    "        self.saved_snapshots = []\n",
    "\n",
    "        # Realistic demand model\n",
    "        self.demand_model = MarkovServiceDemand(self.services)\n",
    "   \n",
    "        self.vehicle_manager = CombinedVehicleManager(\n",
    "            services=self.services,\n",
    "            service_specs=self.service_specs,\n",
    "            target_vehicles=target_vehicles,\n",
    "            demand_model=self.demand_model,\n",
    "            network_file=network_file,\n",
    "            use_gui=use_gui\n",
    "        )\n",
    "\n",
    "        # Load SUMO network to get road positions\n",
    "        self.sumo_net = sumolib.net.readNet(network_file)\n",
    "        self.current_edge_state = None\n",
    "\n",
    "    def _get_optimal_edge_positions(self) -> torch.Tensor:\n",
    "        \"\"\"Calculate optimal edge positions to cover Manhattan\"\"\"\n",
    "        # Get all edges from Manhattan network\n",
    "        sumo_edges = list(self.sumo_net.getEdges())\n",
    "        \n",
    "        # Extract center positions of SUMO edges\n",
    "        edge_positions = []\n",
    "        for edge in sumo_edges:\n",
    "            # Get edge shape (list of points)\n",
    "            shape = edge.getShape()\n",
    "            if len(shape) > 0:\n",
    "                # Calculate edge center\n",
    "                x_coords = [point[0] for point in shape]\n",
    "                y_coords = [point[1] for point in shape]\n",
    "                center_x = sum(x_coords) / len(x_coords)\n",
    "                center_y = sum(y_coords) / len(y_coords)\n",
    "                edge_positions.append((center_x, center_y))\n",
    "        \n",
    "        # If not enough edges found, use node coordinates\n",
    "        if len(edge_positions) < self.num_edges:\n",
    "            nodes = list(self.sumo_net.getNodes())\n",
    "            for node in nodes:\n",
    "                coord = node.getCoord()\n",
    "                if coord:\n",
    "                    edge_positions.append((coord[0], coord[1]))\n",
    "        \n",
    "        # Use simplified k-means to find optimal positions\n",
    "        if len(edge_positions) >= self.num_edges:\n",
    "            # Select most spaced positions\n",
    "            selected_positions = self._select_dispersed_positions(edge_positions, self.num_edges)\n",
    "        else:\n",
    "            # Fallback: circular positions around network center\n",
    "            selected_positions = self._get_circular_positions(self.num_edges)\n",
    "        \n",
    "        return torch.tensor(selected_positions, dtype=torch.float)\n",
    "\n",
    "    def _select_dispersed_positions(self, positions: List[tuple], num_to_select: int) -> List[tuple]:\n",
    "        \"\"\"Select most dispersed positions\"\"\"\n",
    "        if len(positions) <= num_to_select:\n",
    "            return positions\n",
    "        \n",
    "        # Simple method: select most distant positions\n",
    "        selected = [random.choice(positions)]\n",
    "        \n",
    "        for _ in range(1, num_to_select):\n",
    "            max_min_distance = -1\n",
    "            best_candidate = None\n",
    "            \n",
    "            for candidate in positions:\n",
    "                if candidate in selected:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate minimum distance to already selected positions\n",
    "                min_dist = min(self._distance(candidate, sel) for sel in selected)\n",
    "                \n",
    "                if min_dist > max_min_distance:\n",
    "                    max_min_distance = min_dist\n",
    "                    best_candidate = candidate\n",
    "            \n",
    "            if best_candidate:\n",
    "                selected.append(best_candidate)\n",
    "        \n",
    "        return selected\n",
    "\n",
    "    def _get_circular_positions(self, num_positions: int) -> List[tuple]:\n",
    "        \"\"\"Circular positions around network center (fallback)\"\"\"\n",
    "        # Calculate Manhattan network center\n",
    "        nodes = list(self.sumo_net.getNodes())\n",
    "        if nodes:\n",
    "            coords = [node.getCoord() for node in nodes if node.getCoord()]\n",
    "            if coords:\n",
    "                center_x = sum(coord[0] for coord in coords) / len(coords)\n",
    "                center_y = sum(coord[1] for coord in coords) / len(coords)\n",
    "            else:\n",
    "                center_x, center_y = 500, 500\n",
    "        else:\n",
    "            center_x, center_y = 500, 500\n",
    "            \n",
    "        radius = 400  # Larger radius for Manhattan\n",
    "        \n",
    "        positions = []\n",
    "        for i in range(num_positions):\n",
    "            angle = 2 * np.pi * i / num_positions\n",
    "            x = center_x + radius * np.cos(angle)\n",
    "            y = center_y + radius * np.sin(angle)\n",
    "            positions.append((x, y))\n",
    "        \n",
    "        return positions\n",
    "\n",
    "    def _distance(self, pos1: tuple, pos2: tuple) -> float:\n",
    "        \"\"\"Calculate distance between two positions\"\"\"\n",
    "        return np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "\n",
    "    def _get_cloud_position(self, edge_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Position cloud at distance to recover uncovered vehicles\"\"\"\n",
    "        # Calculate edge center of gravity\n",
    "        center_x = torch.mean(edge_positions[:, 0])\n",
    "        center_y = torch.mean(edge_positions[:, 1])\n",
    "        \n",
    "        # Calculate average edge radius\n",
    "        distances_from_center = torch.norm(edge_positions - torch.tensor([center_x, center_y]), dim=1)\n",
    "        mean_radius = torch.mean(distances_from_center)\n",
    "        \n",
    "        # Position cloud at 2x average radius (further for Manhattan)\n",
    "        cloud_distance = mean_radius * 2.0 + 300\n",
    "        \n",
    "        # Arbitrary direction (e.g., northeast)\n",
    "        cloud_x = center_x + cloud_distance * 0.7\n",
    "        cloud_y = center_y + cloud_distance * 0.7\n",
    "        \n",
    "        return torch.tensor([[cloud_x, cloud_y]])\n",
    "\n",
    "    def _init_edges(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Edge initialization with optimal positions\"\"\"\n",
    "        cpu_capacity = torch.full((self.num_edges + 1,), 25)\n",
    "        ram_capacity = torch.full((self.num_edges + 1,), 17)\n",
    "    \n",
    "        # Cloud with more capacity\n",
    "        cpu_capacity[-1] = 150\n",
    "        ram_capacity[-1] = 100\n",
    "        \n",
    "        # Get optimal positions for edges\n",
    "        edge_positions = self._get_optimal_edge_positions()\n",
    "        \n",
    "        # Get cloud position\n",
    "        cloud_position = self._get_cloud_position(edge_positions)\n",
    "        \n",
    "        # Combine positions\n",
    "        positions = torch.cat([edge_positions, cloud_position], dim=0)\n",
    "    \n",
    "        # Initialize services_hosted and TTL_services_hosted\n",
    "        services_hosted = torch.zeros(self.num_edges + 1, len(self.services))\n",
    "        TTL_services_hosted = torch.zeros(self.num_edges + 1, len(self.services))\n",
    "        \n",
    "        # For last edge (cloud), set all services to 1 and TTL to 1000\n",
    "        services_hosted[-1, :] = torch.ones(len(self.services))\n",
    "        TTL_services_hosted[-1, :] = torch.full((len(self.services),), 1000)\n",
    "    \n",
    "        return {\n",
    "            'id': torch.arange(self.num_edges + 1),\n",
    "            'position': positions,\n",
    "            'cpu_capacity': cpu_capacity,\n",
    "            'ram_capacity': ram_capacity,\n",
    "            'cpu_available': cpu_capacity.clone(),\n",
    "            'ram_available': ram_capacity.clone(),\n",
    "            'services_hosted': services_hosted,\n",
    "            'TTL_services_hosted': TTL_services_hosted\n",
    "        }\n",
    "\n",
    "    def _update_services(self, edge_feats: Dict[str, torch.Tensor], \n",
    "                            vehicle_feats: Dict[str, torch.Tensor], \n",
    "                            is_first_snapshot: bool) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Service update with adaptation to realistic demand\"\"\"       \n",
    "        if is_first_snapshot:\n",
    "            edge_feats['cpu_available'] = edge_feats['cpu_capacity'].clone()\n",
    "            edge_feats['ram_available'] = edge_feats['ram_capacity'].clone()\n",
    "    \n",
    "        # Decrement TTL of services deployed in cloud (last edge)\n",
    "        cloud_index = -1  # Cloud index\n",
    "        services_deployed = edge_feats['services_hosted'][cloud_index] > 0\n",
    "        \n",
    "        # Decrement TTL by 1 only for deployed services\n",
    "        edge_feats['TTL_services_hosted'][cloud_index, services_deployed] -= 1\n",
    "    \n",
    "        return edge_feats\n",
    "\n",
    "    def _calculate_local_demand(self, vehicle_feats: Dict[str, torch.Tensor], \n",
    "                              edge_pos: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculate local demand around an edge (only for vehicles with service)\"\"\"\n",
    "        distances = torch.norm(vehicle_feats['position'] - edge_pos, dim=1)\n",
    "        nearby_vehicles = distances < 400  # Larger radius for Manhattan\n",
    "        \n",
    "        if not nearby_vehicles.any():\n",
    "            return torch.zeros(len(self.services))\n",
    "        \n",
    "        # Filter only vehicles with service (exclude 'none')\n",
    "        service_vehicles = vehicle_feats['type_service'] < len(self.services)\n",
    "        valid_nearby = nearby_vehicles & service_vehicles\n",
    "        \n",
    "        if not valid_nearby.any():\n",
    "            return torch.zeros(len(self.services))\n",
    "        \n",
    "        local_service_counts = torch.bincount(\n",
    "            vehicle_feats['type_service'][valid_nearby],\n",
    "            minlength=len(self.services)\n",
    "        )\n",
    "        \n",
    "        return local_service_counts.float() / max(1, valid_nearby.sum())\n",
    "\n",
    "    def generate_snapshot(self, t: int) -> dgl.DGLGraph:\n",
    "        \"\"\"Generate a snapshot\"\"\"\n",
    "        is_first_snapshot = (t == 0)\n",
    "        if self.current_edge_state is None:\n",
    "            self.current_edge_state = self._init_edges()\n",
    "\n",
    "        vehicle_feats = self.vehicle_manager.update(t)\n",
    "        num_vehicles = len(vehicle_feats['id'])\n",
    "\n",
    "        updated_edge_feats = self._update_services(\n",
    "            copy.deepcopy(self.current_edge_state), vehicle_feats, is_first_snapshot\n",
    "        )\n",
    "        self.current_edge_state = updated_edge_feats\n",
    "\n",
    "        # Graph construction\n",
    "        dist_matrix = torch.cdist(vehicle_feats['position'], updated_edge_feats['position'][:-1])\n",
    "        connections = (dist_matrix < 150).nonzero(as_tuple=False)\n",
    "\n",
    "        connected_vehicles = set(connections[:, 0].tolist())\n",
    "        all_vehicles = set(range(num_vehicles))\n",
    "        unconnected_vehicles = list(all_vehicles - connected_vehicles)\n",
    "\n",
    "        cloud_idx = self.num_edges\n",
    "        cloud_edges_src = torch.tensor(unconnected_vehicles, dtype=torch.long)\n",
    "        cloud_edges_dst = torch.full((len(unconnected_vehicles),), cloud_idx, dtype=torch.long)\n",
    "\n",
    "        if len(connections) > 0:\n",
    "            src = torch.cat([connections[:, 0], cloud_edges_src])\n",
    "            dst = torch.cat([connections[:, 1], cloud_edges_dst])\n",
    "        else:\n",
    "            src = cloud_edges_src\n",
    "            dst = cloud_edges_dst\n",
    "\n",
    "        g = dgl.heterograph({\n",
    "            ('vehicle', 'connects', 'edge'): (src, dst)\n",
    "        }, num_nodes_dict={\n",
    "            'vehicle': num_vehicles,\n",
    "            'edge': self.num_edges + 1\n",
    "        })\n",
    "\n",
    "        g.nodes['edge'].data.update(updated_edge_feats)\n",
    "        g.nodes['vehicle'].data.update(vehicle_feats)\n",
    "\n",
    "        if len(src) > 0:\n",
    "            # ‚úÖ CORRECTION: Clearly separate features by connection type\n",
    "            edge_features_list = []\n",
    "            \n",
    "            # 1. Features for NORMAL connections (edge -> vehicle)\n",
    "            if len(connections) > 0:\n",
    "                normal_src = connections[:, 0]\n",
    "                normal_dst = connections[:, 1]\n",
    "                normal_distances = dist_matrix[normal_src, normal_dst]\n",
    "                \n",
    "                # Get CORRECT features for each normal edge\n",
    "                normal_bandwidth = torch.full((len(connections),), 100.0)\n",
    "                \n",
    "                edge_features_list.append({\n",
    "                    'type': 'normal',\n",
    "                    'src': normal_src,\n",
    "                    'dst': normal_dst, \n",
    "                    'bandwidth': normal_bandwidth,\n",
    "                    'distance': normal_distances,\n",
    "                })\n",
    "    \n",
    "            # 2. Features for CLOUD connections (cloud -> vehicle)\n",
    "            if len(unconnected_vehicles) > 0:\n",
    "                cloud_src = cloud_edges_src\n",
    "                cloud_dst = cloud_edges_dst\n",
    "                cloud_distances = torch.full((len(unconnected_vehicles),), 1500.0)\n",
    "                \n",
    "                # Cloud-specific features\n",
    "                cloud_bandwidth = torch.full((len(unconnected_vehicles),), 15.0)\n",
    "                \n",
    "                edge_features_list.append({\n",
    "                    'type': 'cloud', \n",
    "                    'src': cloud_src,\n",
    "                    'dst': cloud_dst,\n",
    "                    'bandwidth': cloud_bandwidth,\n",
    "                    'distance': cloud_distances,\n",
    "                })\n",
    "    \n",
    "            # 3. Combine ALL features with CORRECT matching\n",
    "            all_bandwidth = torch.cat([feat['bandwidth'] for feat in edge_features_list])\n",
    "            all_distances = torch.cat([feat['distance'] for feat in edge_features_list])\n",
    "\n",
    "    \n",
    "            # 5. Assign in CORRECT order\n",
    "            g.edges['connects'].data.update({\n",
    "                'bandwidth': all_bandwidth,\n",
    "                'distance': all_distances, \n",
    "            })\n",
    "    \n",
    "        if self.save_snapshots:\n",
    "            self.saved_snapshots.append(g)\n",
    "        return g\n",
    "\n",
    "    def generate(self) -> List[dgl.DGLGraph]:\n",
    "        return [self.generate_snapshot(t) for t in range(self.time_steps)]\n",
    "    \n",
    "    def save_snapshots_to_file(self):\n",
    "        \"\"\"Save all snapshots to binary file\"\"\"\n",
    "        if not self.save_snapshots or not self.saved_snapshots:\n",
    "            print(\"‚ùå No snapshots to save\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # ‚úÖ Use directly self.saved_snapshots which has already been filtered\n",
    "            dgl.save_graphs(self.output_file, self.saved_snapshots)\n",
    "            print(f\"‚úÖ {len(self.saved_snapshots)} snapshots saved in {self.output_file}\")\n",
    "            \n",
    "            # Statistics\n",
    "            total_vehicles = sum(g.number_of_nodes('vehicle') for g in self.saved_snapshots)\n",
    "            total_edges = sum(g.number_of_edges() for g in self.saved_snapshots)\n",
    "            print(f\"üìä Total: {total_vehicles} vehicles, {total_edges} connections\")\n",
    "            \n",
    "            # Display range of saved snapshots\n",
    "            if self.saved_snapshots:\n",
    "                print(f\"üìÖ Saved snapshots: 1 to {len(self.saved_snapshots)} (snapshot 0 was ignored)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Save error: {e}\")\n",
    "\n",
    "    def visualize_snapshot(self, g: dgl.DGLGraph, snapshot_id: int):\n",
    "        \"\"\"Visualization with NetworkX\"\"\"\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        nx_g = nx.Graph()\n",
    "\n",
    "        vehicle_type_colors = {\n",
    "            0: 'red',      # Car\n",
    "            1: 'blue',     # Truck\n",
    "            2: 'green',    # Bus\n",
    "            3: 'orange',   # Motorcycle\n",
    "            4: 'purple',   # Emergency vehicle\n",
    "            'edge': 'gray',\n",
    "            'cloud': 'black'\n",
    "        }\n",
    "        \n",
    "        service_colors = {\n",
    "            0: 'lightcoral',    # streaming\n",
    "            1: 'lightblue',     # navigation  \n",
    "            2: 'lightgreen',    # iot\n",
    "            3: 'gold',          # diagnostic\n",
    "            4: 'violet',        # securite\n",
    "            5: 'white'          # none\n",
    "        }\n",
    "\n",
    "        # Add nodes\n",
    "        for ntype in g.ntypes:\n",
    "            if ntype == 'vehicle' and 'vehicle_type' in g.nodes[ntype].data:\n",
    "                positions = g.nodes[ntype].data['position'].cpu().numpy()\n",
    "                vehicle_types = g.nodes[ntype].data['vehicle_type'].cpu().numpy()\n",
    "                service_types = g.nodes[ntype].data['type_service'].cpu().numpy() if 'type_service' in g.nodes[ntype].data else [5] * g.number_of_nodes(ntype)\n",
    "                vehicle_ids = g.nodes[ntype].data['id'].cpu().numpy() if 'id' in g.nodes[ntype].data else range(g.number_of_nodes(ntype))\n",
    "                \n",
    "                for i in range(g.number_of_nodes(ntype)):\n",
    "                    node_id = f\"V{int(vehicle_ids[i])}\"\n",
    "                    vehicle_type = int(vehicle_types[i])\n",
    "                    service_type = int(service_types[i])\n",
    "                    \n",
    "                    # Color based on service\n",
    "                    color = service_colors.get(service_type, 'white')\n",
    "                    edge_color = vehicle_type_colors.get(vehicle_type, 'pink')\n",
    "                    \n",
    "                    nx_g.add_node(node_id, \n",
    "                                pos=positions[i], \n",
    "                                ntype=ntype,\n",
    "                                vehicle_type=vehicle_type,\n",
    "                                service_type=service_type,\n",
    "                                color=color,\n",
    "                                edge_color=edge_color,\n",
    "                                size=200 if service_type == 5 else 250)\n",
    "            \n",
    "            elif ntype == 'edge':\n",
    "                positions = g.nodes[ntype].data['position'].cpu().numpy()\n",
    "                edge_ids = g.nodes[ntype].data['id'].cpu().numpy() if 'id' in g.nodes[ntype].data else range(g.number_of_nodes(ntype))\n",
    "                \n",
    "                for i in range(g.number_of_nodes(ntype)):\n",
    "                    if i == g.number_of_nodes(ntype) - 1:\n",
    "                        node_id = \"Cloud\"\n",
    "                        color = vehicle_type_colors['cloud']\n",
    "                        size = 500\n",
    "                    else:\n",
    "                        node_id = f\"E{int(edge_ids[i])}\"\n",
    "                        color = vehicle_type_colors['edge']\n",
    "                        size = 350\n",
    "                    \n",
    "                    nx_g.add_node(node_id, \n",
    "                                pos=positions[i], \n",
    "                                ntype=ntype,\n",
    "                                color=color,\n",
    "                                size=size)\n",
    "\n",
    "        # Add edges\n",
    "        for etype in g.etypes:\n",
    "            vehicle_ids = g.nodes['vehicle'].data['id'].cpu().numpy()\n",
    "            edge_ids = g.nodes['edge'].data['id'].cpu().numpy()\n",
    "\n",
    "            src, dst = g.edges(etype=etype)\n",
    "            src = src.cpu().numpy()\n",
    "            dst = dst.cpu().numpy()\n",
    "\n",
    "            for i in range(len(src)):\n",
    "                src_type, _, dst_type = g.to_canonical_etype(etype)\n",
    "\n",
    "                if src_type == 'vehicle':\n",
    "                    src_id = f\"V{vehicle_ids[src[i]]}\"\n",
    "                else:\n",
    "                    if src[i] == g.number_of_nodes('edge') - 1:\n",
    "                        src_id = \"Cloud\"\n",
    "                    else:\n",
    "                        src_id = f\"E{edge_ids[src[i]]}\"\n",
    "\n",
    "                if dst_type == 'vehicle':\n",
    "                    dst_id = f\"V{vehicle_ids[dst[i]]}\"\n",
    "                else:\n",
    "                    if dst[i] == g.number_of_nodes('edge') - 1:\n",
    "                        dst_id = \"Cloud\"\n",
    "                    else:\n",
    "                        dst_id = f\"E{edge_ids[dst[i]]}\"\n",
    "\n",
    "                if src_id in nx_g and dst_id in nx_g:\n",
    "                    nx_g.add_edge(src_id, dst_id, etype=etype)\n",
    "\n",
    "        # Draw graph\n",
    "        if len(nx_g.nodes()) == 0:\n",
    "            print(\"No nodes to display\")\n",
    "            plt.close()\n",
    "            return\n",
    "        \n",
    "        pos = {node: data.get('pos', (0, 0)) for node, data in nx_g.nodes(data=True)}\n",
    "        colors = [data.get('color', 'pink') for node, data in nx_g.nodes(data=True)]\n",
    "        edge_colors = [data.get('edge_color', 'black') for node, data in nx_g.nodes(data=True)]\n",
    "        sizes = [data.get('size', 300) for node, data in nx_g.nodes(data=True)]\n",
    "\n",
    "        # Draw nodes with colored border\n",
    "        nx.draw_networkx_nodes(nx_g, pos, node_color=colors, node_size=sizes, \n",
    "                              edgecolors=edge_colors, linewidths=2, alpha=0.8)\n",
    "        \n",
    "        if len(nx_g.nodes()) < 50:\n",
    "            labels = {node: node for node in nx_g.nodes()}\n",
    "            nx.draw_networkx_labels(nx_g, pos, labels, font_size=8, font_weight='bold')\n",
    "        \n",
    "        nx.draw_networkx_edges(nx_g, pos, alpha=0.3, edge_color='gray', width=1.5)\n",
    "\n",
    "        # Improved legend\n",
    "        legend_elements = [\n",
    "\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', \n",
    "                      markeredgecolor='red', markersize=10, label='Cooperative Perception'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', \n",
    "                      markeredgecolor='blue', markersize=10, label='Platooning Control'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', \n",
    "                      markeredgecolor='green', markersize=10, label='Edge-Assisted Object Recognition'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gold', \n",
    "                      markeredgecolor='orange', markersize=10, label='Predictive Collision Avoidance'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='violet', \n",
    "                      markeredgecolor='purple', markersize=10, label='Infrastructure-Assisted Vision'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='white', \n",
    "                      markeredgecolor='black', markersize=10, label='No service'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', \n",
    "                      markersize=10, label='Edge'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='black', \n",
    "                      markersize=10, label='Cloud')\n",
    "        ]\n",
    "        \n",
    "        plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "        plt.title(f\"Snapshot {snapshot_id} - Manhattan with Services\\n(V=Vehicle, E=Edge, Color=interior=service, border=vehicle type)\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Statistics\n",
    "        num_with_service = sum(1 for node, data in nx_g.nodes(data=True) \n",
    "                              if data.get('ntype') == 'vehicle' and data.get('service_type', 5) != 5)\n",
    "        \n",
    "        print(f\"\\nSnapshot {snapshot_id}:\")\n",
    "        print(f\"Nodes: {len(nx_g.nodes())}, Edges: {len(nx_g.edges())}\")\n",
    "        print(f\"Vehicles: {g.number_of_nodes('vehicle')}, Edges: {g.number_of_nodes('edge')}\")\n",
    "        print(f\"Vehicles with service: {num_with_service}/{g.number_of_nodes('vehicle')}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main script with saving and visualization\"\"\"\n",
    "    \n",
    "    print(\"üöÄ STARTING SIMULATION WITH YOUR EXISTING NETWORK\")\n",
    "    \n",
    "    # Configuration\n",
    "    services = [\n",
    "        'cooperative_perception', \n",
    "        'platooning_control', \n",
    "        'edge_object_recognition',\n",
    "        'predictive_collision_avoidance',\n",
    "        'infrastructure_vision'\n",
    "    ]\n",
    "\n",
    "    demand_model = MarkovServiceDemany(services)\n",
    "    \n",
    "    # ‚úÖ SIMULATOR WITH SAVING\n",
    "    simulator = CombinedDocumentSimulator(\n",
    "        num_edges=7,\n",
    "        target_vehicles=20,\n",
    "        time_steps=200, \n",
    "        network_file=\"manhattan.net.xml\",\n",
    "        use_gui=True,\n",
    "        save_snapshots=True,\n",
    "        output_file=\"manhattan_snapshots.bin\"\n",
    "    )\n",
    "\n",
    "    # Snapshot generation WITH FILTERING\n",
    "    print(\"‚è≥ Generating and saving snapshots...\")\n",
    "    \n",
    "    graphs = []\n",
    "    for t in range(simulator.time_steps):\n",
    "        g = simulator.generate_snapshot(t)\n",
    "        \n",
    "        # ‚úÖ OPTION 3: Ignore first snapshot if no vehicles\n",
    "        if t == 0 and g.number_of_nodes('vehicle') == 0:\n",
    "            print(\"‚è≠Ô∏è  Snapshot 0 ignored (no vehicles)\")\n",
    "            continue\n",
    "            \n",
    "        graphs.append(g)\n",
    "        \n",
    "        # Graphical visualization of some snapshots\n",
    "        if t % 10 == 0 and g.number_of_nodes('vehicle') > 0:  # ‚úÖ Ensure there are vehicles\n",
    "            print(f\"üé® Graphical visualization of snapshot {t}\")\n",
    "            simulator.visualize_snapshot(g, t)\n",
    "    \n",
    "    # ‚úÖ FINAL SAVING with filtered graphs\n",
    "    simulator.saved_snapshots = graphs  # Replace with graphs without empty snapshot\n",
    "    simulator.save_snapshots_to_file()\n",
    "    \n",
    "    # ‚úÖ FEATURES VISUALIZATION\n",
    "    print(\"\\nüìä NODE FEATURES VISUALIZATION\")\n",
    "    visualize_all_nodes_features(graphs)\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "def visualize_all_nodes_features(glist):\n",
    "    \"\"\"Visualize all node features for each snapshot\"\"\"\n",
    "    for t, g in enumerate(glist):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"=== SNAPSHOT {t} ===\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # 1. Display Edge node data\n",
    "        if 'edge' in g.ntypes and g.number_of_nodes('edge') > 0:\n",
    "            edge_data = {}\n",
    "            for k, v in g.nodes['edge'].data.items():\n",
    "                # Convert tensors to numpy and flatten 2D+ arrays\n",
    "                if v.ndim > 1:\n",
    "                    for i in range(v.shape[1]):\n",
    "                        edge_data[f\"{k}_{i}\"] = v[:, i].numpy()\n",
    "                else:\n",
    "                    edge_data[k] = v.numpy()\n",
    "\n",
    "            edge_df = pd.DataFrame(edge_data)\n",
    "            edge_df.index.name = 'Edge_ID'\n",
    "            print(\"\\nüì° EDGE NODES FEATURES:\")\n",
    "            print(edge_df)\n",
    "            \n",
    "            # Additional statistics for edges\n",
    "            print(f\"\\nüìà Edge Statistics - Snapshot {t}:\")\n",
    "            print(f\"Number of edges: {g.number_of_nodes('edge')}\")\n",
    "            if 'cpu_available' in g.nodes['edge'].data:\n",
    "                cpu_avail = g.nodes['edge'].data['cpu_available'].numpy()\n",
    "                ram_avail = g.nodes['edge'].data['ram_available'].numpy()\n",
    "                print(f\"Average available CPU: {cpu_avail.mean():.2f}\")\n",
    "                print(f\"Average available RAM: {ram_avail.mean():.2f}\")\n",
    "\n",
    "        # 2. Display Vehicle node data\n",
    "        if 'vehicle' in g.ntypes and g.number_of_nodes('vehicle') > 0:\n",
    "            vehicle_data = {}\n",
    "            for k, v in g.nodes['vehicle'].data.items():\n",
    "                if v.ndim > 1:\n",
    "                    for i in range(v.shape[1]):\n",
    "                        vehicle_data[f\"{k}_{i}\"] = v[:, i].numpy()\n",
    "                else:\n",
    "                    vehicle_data[k] = v.numpy()\n",
    "\n",
    "            vehicle_df = pd.DataFrame(vehicle_data)\n",
    "            vehicle_df.index.name = 'Vehicle_ID'\n",
    "            print(\"\\nüöó VEHICLE NODES FEATURES:\")\n",
    "            print(vehicle_df)\n",
    "            \n",
    "            # Additional statistics for vehicles\n",
    "            print(f\"\\nüìä Vehicle Statistics - Snapshot {t}:\")\n",
    "            print(f\"Number of vehicles: {g.number_of_nodes('vehicle')}\")\n",
    "            if 'type_service' in g.nodes['vehicle'].data:\n",
    "                services = g.nodes['vehicle'].data['type_service'].numpy()\n",
    "                unique, counts = np.unique(services, return_counts=True)\n",
    "                service_names = [\n",
    "                    'cooperative_perception', \n",
    "                    'platooning_control', \n",
    "                    'edge_object_recognition', \n",
    "                    'predictive_collision_avoidance', \n",
    "                    'infrastructure_vision', \n",
    "                    'none'\n",
    "                ]\n",
    "                print(\"Service distribution:\")\n",
    "                for service_id, count in zip(unique, counts):\n",
    "                    service_name = service_names[service_id] if service_id < len(service_names) else 'unknown'\n",
    "                    print(f\"  {service_name}: {count} vehicles\")\n",
    "\n",
    "        # 3. Display edge data\n",
    "        if g.number_of_edges() > 0:\n",
    "            print(f\"\\nüîó CONNECTIONS - Snapshot {t}:\")\n",
    "            print(f\"Total connections: {g.number_of_edges()}\")\n",
    "            \n",
    "            # Count connections to cloud vs local edges\n",
    "            if 'edge' in g.ntypes and 'vehicle' in g.ntypes:\n",
    "                cloud_idx = g.number_of_nodes('edge') - 1\n",
    "                edge_connections = 0\n",
    "                cloud_connections = 0\n",
    "                \n",
    "                for etype in g.etypes:\n",
    "                    src, dst = g.edges(etype=etype)\n",
    "                    for d in dst.numpy():\n",
    "                        if d == cloud_idx:\n",
    "                            cloud_connections += 1\n",
    "                        else:\n",
    "                            edge_connections += 1\n",
    "                \n",
    "                print(f\"Connections to local edges: {edge_connections}\")\n",
    "                print(f\"Connections to cloud: {cloud_connections}\")\n",
    "                print(f\"Local connection rate: {edge_connections/(edge_connections+cloud_connections)*100:.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graphs = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
